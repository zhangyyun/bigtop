# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
HADOOP_NAME="datanode"
DAEMON="hadoop-hdfs-$HADOOP_NAME"
DESC="Hadoop $HADOOP_NAME"
EXEC_PATH="\$HADOOP_HOME/sbin/hadoop-daemon.sh"
SVC_USER="\${SVC_USER:-hdfs}"
WORKING_DIR="\$HADOOP_HOME"
DAEMON_FLAGS="$HADOOP_NAME"
CONF_DIR=""\${HADOOP_HOME}/conf""
PIDFILE="\$HADOOP_PID_DIR/hadoop-\$SVC_USER-\$SERVICE_NAME.pid"

generate_start() {

cat <<'__EOT__'
start() {
  [ -x $EXEC_PATH ] || exit $ERROR_PROGRAM_NOT_INSTALLED
  [ -d $CONF_DIR ] || exit $ERROR_PROGRAM_NOT_CONFIGURED

  # HADOOP_SECURE_DN_USER is being read from hadoop-env.sh
  # Setting the TARGET_USER for usages.
  if [ -n "$HADOOP_SECURE_DN_USER" ]; then
    TARGET_USER=root
  else
    TARGET_USER=${HADOOP_DATANODE_USER:-$SVC_USER}
  fi

  export HADOOP_IDENT_STRING=$TARGET_USER
  su -s /bin/bash $TARGET_USER -c "$EXEC_PATH --config '$CONF_DIR' start $DAEMON_FLAGS"

  # Some processes are slow to start
  sleep $SLEEP_TIME
  checkstatusofproc
  RETVAL=$?

  if [ $RETVAL -eq $STATUS_RUNNING ]; then
    touch $LOCKFILE
    log_success_msg "Started ${DESC} (${DAEMON}): "
  else
    log_failure_msg "Failed to start ${DESC}. Return value: $RETVAL"
  fi

  return $RETVAL
}
__EOT__

}

generate_extra_commands() {

cat <<'__EOT__'
    rollback)
      DAEMON_FLAGS="$DAEMON_FLAGS -${1}"
      start
      ;;
    *)
      echo $"Usage: $0 {start|stop|status|restart|try-restart|condrestart|rollback}"
      exit 1
__EOT__

}

hook_commands() {

cat <<__EOT__
SERVICE_NAME="${HADOOP_NAME}"
export HADOOP_HOME="/usr/hdp/current/hadoop-hdfs-\$SERVICE_NAME/../hadoop"

SVC_USER="$SVC_USER"
USER="\${SVC_USER}"
CONF_DIR="\${HADOOP_HOME}/conf"
. \$CONF_DIR/hadoop-env.sh

HADOOP_PID_DIR="\${HADOOP_PID_DIR:-/var/run/hadoop/\$SVC_USER}"
HADOOP_LOG_DIR="\${HADOOP_LOG_DIR:-/var/log/hadoop/\$SVC_USER}"
install -d -m 0755 -o \${SVC_USER} -g \${SVC_USER} \${HADOOP_PID_DIR} 1>/dev/null 2>&1 || :
install -d -m 0755 -o \${SVC_USER} -g \${SVC_USER} \${HADOOP_LOG_DIR} 1>/dev/null 2>&1 || :

__EOT__

}
